{describe, it, expect, to_equal} = import '@fink/jest/test.fnk'

{slice} = import '@fink/std-lib/str.fnk'
{match_all, rx, split} = import '@fink/std-lib/regex.fnk'
{length} = import '@fink/std-lib/iter.fnk'

{init_parser, start_parser} = import './parser.fnk'
{curr_value, curr_loc} = import './parser.fnk'
{next_is, next_is_end, next_loc} = import './parser.fnk'
{advance, expression} = import './parser.fnk'

{add_separator, add_operator, add_identifier, add_literal} = import './expressions.fnk'
{add_ignorable, left_binding, non_binding} = import './expressions.fnk'



literal = fn type:
  dict:
    ...left_binding type

    nud: fn: fn ctx:
      value = curr_value ctx
      [{type, value}, ctx]



infix = fn token_type:
  dict:
    ...left_binding token_type

    led: fn lbp: fn ctx, left:
      op = curr_value ctx
      [right, next_ctx] = expression ctx, lbp
      [{type: 'infx', op, left, right}, next_ctx]



prefix = fn token_type:
  dict:
    ...left_binding token_type

    nud: fn lbp: fn ctx:
      op = curr_value ctx
      [right, next_ctx] = expression ctx, lbp
      [{type: 'prefix', op, right}, next_ctx]



string = fn token_type:
  dict:
    ...left_binding token_type

    nud: fn: fn ctx:
      value = curr_value ctx
      [{type: 'string',  value}, ctx]



init_test_lang = fn ctx:
  pipe ctx:
    add_ignorable 'whitespace'

    add_identifier literal 'ident'

    add_literal literal 'number'
    add_literal string 'string'

    add_operator infix '='
    add_operator prefix '!'
    add_separator non_binding ';'





get_loc = fn start, text:
  text_len = length text
  lines = split text, rx'\n'
  lines_len = length lines

  line = start.line - 1 + lines_len
  column = match lines_len:
    1:
      start.column + text_len
    else:
      [..., last] = lines
      length last

  {pos: start.pos + text_len, line, column}



tokenize = fn code:
  lex = rx'
    ^(
      (?<whitespace>\s+)
      |(?<comment>#.*?\n)
      |(?<string>\'.*?(\'|$))
      |(?<assign>=)
      |(?<operator>[!])
      |(?<terminator>[;])
      |(?<number>[0-9]+)
      |(?<ident>\w+)
      |(?<other>.)
      |(?<end>$)
    )
  '

  ctx = rec:
    code
    curly_count: 0
    start: {pos: 0, line: 1, column: 0}

  pipe ctx:
    unfold , {code, start}=ctx:
      code_slice = slice code, start.pos
      [matched] = match_all code_slice, lex
      [value] = matched

      end = get_loc start, value
      type = match matched.groups:
        {string: {}}: 'string'
        {comment: {}}: 'comment'
        {whitespace: {}}: 'whitespace'
        {ident: {}}: 'ident'
        {number: {}}: 'number'
        {other: {}}: 'other'
        {end: {}}: 'end'
        else: value

      token = {type, value, loc: {start, end}}

      acc = rec:
        code
        start: end

      [token, acc]



parse = fn code:
  tokens = tokenize code

  ctx = pipe {code, filename: 'test.fnk', tokens}:
    init_parser
    init_test_lang
    start_parser

  expression ctx, 0



describe 'parser', fn:
  it 'parses simple expression', fn:
    [ast, ctx] = parse 'foobar = !123'

    expect
      ast
      to_equal
        rec:
          type: 'infx'
          op: '='
          left: rec:
            type: 'ident'
            value: 'foobar'

          right: rec:
            type: 'prefix'
            op: '!'
            right: rec:
              type: 'number'
              value: '123'

    expect
      next_is_end ctx
      to_equal true


  it 'parses string collecting text to end of string', fn:
    [ast, ctx] = parse "' foobar = 123 '"

    expect
      ast
      to_equal
        rec:
          type: 'string'
          value: "' foobar = 123 '"

    expect
      next_is_end ctx
      to_equal true



describe 'curr token tests, values, and assertions', fn:

  it 'checks if current token value', fn:
    [, ctx] = parse 'foobar = 123'

    expect
      curr_value ctx
      to_equal '123'


  it 'gets current token loc', fn:
    [, ctx] = parse 'foobar = 123'

    expect
      curr_loc ctx
      to_equal
        rec:
          start: {column: 9, line: 1, pos: 9}
          end: {column: 12, line: 1, pos: 12}




describe 'next token tests and assertions', fn:
  it 'checks if next token value is same as expected', fn:
    [, ctx] = parse 'foobar = 123;'

    expect
      next_is ctx, ';'
      to_equal true


  it 'gets next token loc', fn:
    [, ctx] = parse 'foobar = 123'

    expect
      next_loc ctx
      to_equal
        rec:
          start: {column: 12, line: 1, pos: 12}
          end: {column: 12, line: 1, pos: 12}



describe 'advance to next token', fn:

  it 'advances to end token', fn:
    [, ctx0] = parse 'foobar = 123'
    ctx1 = advance ctx0

    expect
      next_is_end ctx0
      to_equal true

    expect
      next_is_end ctx1
      to_equal true


  # it 'errors when next token value is unexpected', fn:
  #   [, ctx] = parse 'foobar = 123; shrub = ni'

  #   {errors: [{error}]} = advance ctx, '=='



describe 'handles errors', fn:
  it 'unexpected end of code', fn:
    [, {errors: [{error}]}] = parse 'foobar ='

    expect
      error
      to_equal '
        test.fnk:1:7
        1| foobar =
                  ^

        Unexpected end of code.
        '


  it 'unexpected infix', fn:
    [, {errors: [{error}]}] = parse '= 123'

    expect
      error
      to_equal '
        test.fnk:1:0
        1| = 123
           ^

        Unexpected token `=` at start of expression.
        '


  it 'using prefix operator as infix operator', fn:
    [, {errors: [{error}]}] = parse 'foo ! ni'

    expect
      error
      to_equal '
        test.fnk:1:4
        1| foo ! ni
               ^

        Cannot use `!` as an infix operator.
        '


  it 'using other as infix operator', fn:
    [, {errors: [{error}]}] = parse 'foo = spam ni'

    expect
      error
      to_equal "
        test.fnk:1:11
        1| foo = spam ni
                      ^

        Cannot use `ni` as an infix operator.
        "

