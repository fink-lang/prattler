{inspect} = import 'util'
{obj_has} = import '@fink/std-lib/obj'

{add_token} = import './tokenizer'
{add_error} = import './errors'


# TODO: this only works because '' can never be a token value
other_token_value = ''
auto = {auto: true}


symbol = fn token_value: dict:
  token_value

  lbp: fn lbp: fn: lbp
# nud: not-set
# led: not-set

other_symbol = dict:
  token_value: other_token_value
  lbp: fn lbp: fn: lbp


init_symbols = fn: dict:
  next_lbp: 2
  lbps: {}
  nuds: {}
  leds: {}
  igns: {}


add_symbol = fn symb, lbp, is_sep: fn {symbols, tokenizer, ...ctx}:
  {next_lbp, lbps, nuds, leds} = symbols

  symb_lbp = match lbp:
    auto: next_lbp
    else: lbp

  next_lbps = {...lbps, (symb.token_value): symb.lbp symb_lbp}

  next_nuds = match symb.nud:
    # TODO: {} should be a match operator: callable
    {}: {...nuds, (symb.token_value): symb.nud symb_lbp}
    else: nuds

  next_leds = match symb.led:
    # TODO: {} should be a match operator: callable
    {}: {...leds, (symb.token_value): symb.led symb_lbp}
    else: leds

  next_tokenizer = pipe tokenizer:
    add_token symb.token_value, is_sep

  dict:
    ...ctx
    tokenizer: next_tokenizer
    symbols: dict:
      next_lbp: next_lbp + 2
      lbps: next_lbps
      nuds: next_nuds
      leds: next_leds


add_whitespace = fn token_val: fn {tokenizer, igns, ...ctx}:
  next_tokenizer = pipe tokenizer:
    add_token token_val, true

  dict:
    ...ctx
    tokenizer: next_tokenizer
    igns: {...igns, (token_val): true}


add_separator = fn symb: add_symbol symb, 0, true


add_operator = fn symb: add_symbol symb, auto, true


# TODO: keep it or just have add_identifier, add_keyword
# istanbul ignore next
add_non_separating = fn symb: add_symbol symb, auto, false
add_identifier = fn symb: add_symbol symb, auto, false
# istanbul ignore next
add_keyword = fn symb: add_symbol symb, auto, false

# TODO: add_comment


curr_is_separator = fn ctx:
  {curr_token, tokenizer: {separators}} = ctx
  obj_has separators, curr_token.value


ignorable = fn ctx, token:
  match token && obj_has ctx.igns, token.value:
    true: true
    else: false


error_nud = fn ctx:
  {curr_token} = ctx
  {value} = curr_token

  add_error ctx,
    `Unexpected token '${value}' at start of expression.`
    curr_token


error_led = fn ctx:
  {curr_token} = ctx
  {value} = curr_token

  add_error ctx,
    `Cannot use ${inspect value} as an infix operator.`
    curr_token


nud = fn ctx:
  {curr_token, symbols: {nuds}} = ctx
  {value} = curr_token

  nud_fn = match true:
    obj_has nuds, value:
      nuds.(value)

    # TODO: should error_nud just be a nud func on seperators?
    curr_is_separator ctx:
      error_nud

    else:
      nuds.(other_token_value)

  nud_fn ctx


led = fn ctx, left:
  {curr_token, symbols: {leds}} = ctx
  {value} = curr_token

  led_fn = match true:
    obj_has leds, value:
      leds.(value)

    curr_is_separator ctx:
      error_led

    # istanbul ignore next
    obj_has leds, other_token_value:
      leds.(other_token_value)

    else:
      error_led

  led_fn ctx, left


next_lbp = fn ctx, left:
  {next_token, symbols: {lbps}} = ctx
  {value} = next_token

  lbp_fn = match next_token:
    {end: true}:
      fn: 0

    obj_has lbps, ?.value:
      lbps.(value)

    else:
      # any other_token_value will act like a separator by default
      # so it is OK to use it as fallback
      lbps.(other_token_value)

  lbp_fn ctx, left

