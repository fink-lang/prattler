{obj_has} = import '@fink/std-lib/obj.fnk'
{slice, ends_with} = import '@fink/std-lib/str.fnk'
{rx, split, find_index} = import '@fink/std-lib/regex.fnk'
{length, is_empty} = import '@fink/std-lib/iter.fnk'



get_partials = fn [start, ...rest], pre='':
  key = '${pre}${start}'
  match rest:
    is_empty ?:
      {(key): false}
    else:
      partials = get_partials rest, key
      {(key): true, ...partials}



get_next_loc = fn prev_char, {pos, line, column}:
  match prev_char:
    '\n':
      start = {pos: pos, line: line + 1, column: 0}
      end = {pos: pos + 1, line: line + 1, column: 1}
      {start, end}
    else:
      start = {pos: pos, line, column: column}
      end = {pos: pos + 1, line, column: column + 1}
      {start, end}



get_next_char = fn code, prev_loc:
  char = code.(prev_loc.pos)
  prev_char = slice code, prev_loc.pos - 1, prev_loc.pos

  next_loc = get_next_loc prev_char, prev_loc
  [char, next_loc]



handle_end = fn value, start, end, ctx:
  match value:
    '': list:
      {end: true, loc: {start: end, end}}
      {...ctx, partial_token: {value: '', loc: {start, end}}}

    '\n':
      nend = {pos: end.pos, line: end.line+1, column: 0}
      list:
        {value, loc: {start, end}}
        {...ctx, partial_token: {value: '', loc:{start: nend, end: nend}}}

    else:
      list:
        {value, loc: {start, end}}
        {...ctx, partial_token: {value: '', loc: {start, end}}}



get_text = fn ctx, start, stop_at:
  {code} = ctx

  search_text = slice code, start.pos

  idx = find_index search_text, stop_at

  text = match idx:
    -1: slice search_text, 0
    else: slice search_text, 0, idx

  text_len = length text

  lines = split text, rx'\n'
  lines_len = length lines

  line = start.line - 1 + lines_len
  column = match lines_len:
    1:
      start.column + text_len
    else:
      [..., last] = lines
      length last


  end = {pos: start.pos + text_len, line, column}

  partial_token = match text:
    ends_with ?, '\n':
      [value, loc] = get_next_char code, {...end, line: end.line - 1}
      {value, loc}
    else:
      [value, loc] = get_next_char code, end
      {value, loc}

  next_ctx = {...ctx, partial_token}
  [{value: text, loc: {start, end}}, next_ctx]



get_next_token = fn ctx:
  {code, partials, separators, partial_token} = ctx
  {value: start_val, loc: start_loc} = partial_token

  [next_token, next_ctx] = pipe [start_val, start_loc]:
    unfold [value, value_loc]:
      match value_loc:
        {end: {pos: ? < length code}}:
          [char, char_loc] = get_next_char code, value_loc.end
          new_value = '${value}${char}'

          is_seperator = match separators:
            obj_has ?, char: true
            obj_has ?, value: true

          is_partial = obj_has partials, new_value

          match true:
            is_seperator and not is_partial:
              token = {value, loc: {start: value_loc.start, end: value_loc.end}}
              partial_token = {value: char, loc: char_loc}

              next_ctx = {...ctx, partial_token}
              [token, next_ctx, true]
            else:
              ll = {start: value_loc.start, end: char_loc.end}
              [new_value, ll, false]
        else:
          {start, end} = value_loc
          [token, next_ctx] = handle_end value, start, end, ctx
          [token, next_ctx, true]

    find [, , done]:
      done

  [next_token, next_ctx]



init_tokenizer = fn code, filename:
  dict:
    code
    filename
    tokens: {}
    partials: {}
    separators: {}
    partial_token: dict:
      value: ''
      loc: dict:
        start: {pos: 0, line: 1, column: 0}
        end: {pos: 0, line: 1, column: 0}



add_token = fn value, is_sep=true: fn {tokens, partials, separators, ...ctx}:
  next_tokens = {...tokens, (value): {value, is_sep}}

  next_partials = match true:
    is_sep: {...partials, ...get_partials value}
    else: partials

  next_seperators = match true:
    is_sep: {...separators, (value): true}
    else: separators

  dict:
    ...ctx
    tokens: next_tokens
    partials: next_partials
    separators: next_seperators


